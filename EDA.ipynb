{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "212db142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5526e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape: (630000, 13)\n",
      "test.shape: (270000, 12)\n",
      "orig.shape: (20000, 13)\n",
      "11 Base Features:['age', 'gender', 'course', 'study_hours', 'class_attendance', 'internet_access', 'sleep_hours', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, gc\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "orig = pd.read_csv('Exam_Score_Prediction.csv')\n",
    "\n",
    "print(\"train_shape:\",train.shape)\n",
    "print(\"test.shape:\",test.shape)\n",
    "print(\"orig.shape:\",orig.shape)\n",
    "\n",
    "orig\n",
    "\n",
    "# 今後のためにリストを作る\n",
    "target = 'exam_score'\n",
    "base = [col for col in train.columns if col not in ['id', target]]\n",
    "categories = train.select_dtypes('object').columns.to_list()\n",
    "nums = [col for col in base if col not in categories]\n",
    "print(f'{len(base)} Base Features:{base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5970102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 ORIG Features Created.\n"
     ]
    }
   ],
   "source": [
    "ORIG = []\n",
    "\n",
    "# 外部データの各カラムのユニークごとの平均値というカラムを追加する。\n",
    "for col in base:\n",
    "    # 一つの列に対してgroupbyで固有の値をまとめる。それらのtargetをそれぞれ平均する\n",
    "    mean_map = orig.groupby(col)[target].mean() \n",
    "    new_mean_col_name = f\"orig_mean_{col}\"\n",
    "    mean_map.name = new_mean_col_name\n",
    "    \n",
    "    train = train.merge(mean_map, on=col, how='left') # colをキーにして\n",
    "    test = test.merge(mean_map, on=col, how='left')\n",
    "    ORIG.append(new_mean_col_name)\n",
    "    \n",
    "# 外部データの各カラムのユニークごとのサイズというカラムを追加する。\n",
    "    new_count_col_name = f\"orig_count_{col}\"\n",
    "    count_map = orig.groupby(col).size().reset_index(name=new_count_col_name)\n",
    "    \n",
    "    train = train.merge(count_map, on=col, how='left')\n",
    "    test = test.merge(count_map, on=col, how='left')\n",
    "    ORIG.append(new_count_col_name)\n",
    "\n",
    "print(f'{len(ORIG)} ORIG Features Created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8490d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origには存在するが、trainには存在しないカテゴリを全体平均で埋める\n",
    "for col in ORIG:\n",
    "    if 'mean' in col:\n",
    "        train[col] = train[col].fillna(orig[target].mean())\n",
    "        test[col] = test[col].fillna(orig[target].mean())\n",
    "    else:\n",
    "        train[col] = train[col].fillna(0)\n",
    "        test[col] = test[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3406c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce_mem_usage はここに定義（そのままでOK）\n",
    "\n",
    "features = base + ORIG\n",
    "\n",
    "# まず X, y を作る（これが先）\n",
    "X = train[features].copy()\n",
    "y = train[target].copy()\n",
    "\n",
    "# test側も、モデルに入れる列だけにそろえる（重要）\n",
    "X_test = test[features].copy()\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba7f5b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Encoding applied to 6 features.\n",
      "TE_COLS: ['gender', 'course', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n",
      "Index(['age', 'gender', 'course', 'study_hours', 'class_attendance',\n",
      "       'internet_access', 'sleep_hours', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty', 'orig_mean_age', 'orig_count_age',\n",
      "       'orig_mean_gender', 'orig_count_gender', 'orig_mean_course',\n",
      "       'orig_count_course', 'orig_mean_study_hours', 'orig_count_study_hours',\n",
      "       'orig_mean_class_attendance', 'orig_count_class_attendance',\n",
      "       'orig_mean_internet_access', 'orig_count_internet_access',\n",
      "       'orig_mean_sleep_hours', 'orig_count_sleep_hours',\n",
      "       'orig_mean_sleep_quality', 'orig_count_sleep_quality',\n",
      "       'orig_mean_study_method', 'orig_count_study_method',\n",
      "       'orig_mean_facility_rating', 'orig_count_facility_rating',\n",
      "       'orig_mean_exam_difficulty', 'orig_count_exam_difficulty', 'te_gender',\n",
      "       'te_course', 'te_sleep_quality', 'te_study_method',\n",
      "       'te_facility_rating', 'te_exam_difficulty'],\n",
      "      dtype='object')\n",
      "Index(['age', 'gender', 'course', 'study_hours', 'class_attendance',\n",
      "       'internet_access', 'sleep_hours', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty', 'orig_mean_age', 'orig_count_age',\n",
      "       'orig_mean_gender', 'orig_count_gender', 'orig_mean_course',\n",
      "       'orig_count_course', 'orig_mean_study_hours', 'orig_count_study_hours',\n",
      "       'orig_mean_class_attendance', 'orig_count_class_attendance',\n",
      "       'orig_mean_internet_access', 'orig_count_internet_access',\n",
      "       'orig_mean_sleep_hours', 'orig_count_sleep_hours',\n",
      "       'orig_mean_sleep_quality', 'orig_count_sleep_quality',\n",
      "       'orig_mean_study_method', 'orig_count_study_method',\n",
      "       'orig_mean_facility_rating', 'orig_count_facility_rating',\n",
      "       'orig_mean_exam_difficulty', 'orig_count_exam_difficulty', 'te_gender',\n",
      "       'te_course', 'te_sleep_quality', 'te_study_method',\n",
      "       'te_facility_rating', 'te_exam_difficulty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Target Encoding (OOFでリーク防止) + 列選別条件つき\n",
    "# =========================\n",
    "\n",
    "def select_te_cols(\n",
    "    df_train, df_test, cols,\n",
    "    min_unique=3,              # unique <=2 は除外\n",
    "    max_unique_abs=5000,       # 高カーディナリティ除外\n",
    "    max_unique_ratio=0.30,     # unique/行数 が大きすぎる列は除外（ID化）\n",
    "    max_missing=0.60,          # 欠損率が高い列は除外\n",
    "    rare_thr=5,                # レア判定（出現回数<=5）\n",
    "    max_rare_points_ratio=0.80,# レアカテゴリが占める割合が大きい列は除外\n",
    "    max_unseen_ratio=0.20      # testにしかないカテゴリが多い列は除外\n",
    "):\n",
    "    n = len(df_train)\n",
    "    chosen = []\n",
    "    for col in cols:\n",
    "        s_tr = df_train[col]\n",
    "        s_te = df_test[col]\n",
    "\n",
    "        # 欠損\n",
    "        if s_tr.isna().mean() > max_missing:\n",
    "            continue\n",
    "\n",
    "        # unique\n",
    "        nunq = s_tr.nunique(dropna=True)\n",
    "        if nunq < min_unique:\n",
    "            continue\n",
    "        if nunq > max_unique_abs:\n",
    "            continue\n",
    "        if nunq / n > max_unique_ratio:\n",
    "            continue\n",
    "\n",
    "        # レアカテゴリ比率\n",
    "        vc = s_tr.value_counts(dropna=True)\n",
    "        rare_points_ratio = (s_tr.map(vc).fillna(0) <= rare_thr).mean()\n",
    "        if rare_points_ratio > max_rare_points_ratio:\n",
    "            continue\n",
    "\n",
    "        # unseen比率（testにあるがtrainにないカテゴリの比率）\n",
    "        tr_set = set(s_tr.dropna().unique())\n",
    "        te_set = set(s_te.dropna().unique())\n",
    "        if len(te_set) > 0:\n",
    "            unseen_ratio = len(te_set - tr_set) / len(te_set)\n",
    "            if unseen_ratio > max_unseen_ratio:\n",
    "                continue\n",
    "\n",
    "        chosen.append(col)\n",
    "    return chosen\n",
    "\n",
    "\n",
    "def add_target_encoding_oof(train_df, test_df, y, te_cols, n_splits=5, seed=42, smoothing=20):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    for col in te_cols:\n",
    "        te_name = f\"te_{col}\"\n",
    "        train_te = np.zeros(len(train_df), dtype=np.float64)\n",
    "        test_te_folds = []\n",
    "\n",
    "        for tr_idx, va_idx in kf.split(train_df):\n",
    "            X_tr = train_df.iloc[tr_idx]\n",
    "            y_tr = y.iloc[tr_idx]\n",
    "            X_va = train_df.iloc[va_idx]\n",
    "\n",
    "            prior = y_tr.mean()\n",
    "\n",
    "            stats = (\n",
    "                pd.DataFrame({col: X_tr[col].values, \"y\": y_tr.values})\n",
    "                .groupby(col)[\"y\"]\n",
    "                .agg([\"mean\", \"count\"])\n",
    "            )\n",
    "\n",
    "            smooth_map = (stats[\"count\"] * stats[\"mean\"] + smoothing * prior) / (stats[\"count\"] + smoothing)\n",
    "\n",
    "            train_te[va_idx] = X_va[col].map(smooth_map).fillna(prior).astype(np.float64).values\n",
    "            test_te_folds.append(test_df[col].map(smooth_map).fillna(prior).astype(np.float64).values)\n",
    "\n",
    "        train_df[te_name] = train_te\n",
    "        test_df[te_name] = np.mean(np.vstack(test_te_folds), axis=0)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# ---- ここがあなたのコードの差し替え部分 ----\n",
    "\n",
    "# TE対象を「object列のうち、条件を満たす列」に絞る\n",
    "TE_COLS_RAW = categories\n",
    "TE_COLS = select_te_cols(\n",
    "    train, test, TE_COLS_RAW,\n",
    "    min_unique=3,\n",
    "    max_unique_abs=5000,\n",
    "    max_unique_ratio=0.30,\n",
    "    max_missing=0.60,\n",
    "    rare_thr=5,\n",
    "    max_rare_points_ratio=0.80,\n",
    "    max_unseen_ratio=0.20\n",
    ")\n",
    "print(f\"Target Encoding applied to {len(TE_COLS)} features.\")\n",
    "print(\"TE_COLS:\", TE_COLS)\n",
    "\n",
    "# OOF TE作成\n",
    "train, test = add_target_encoding_oof(train, test, y, TE_COLS, n_splits=5, seed=42, smoothing=20)\n",
    "\n",
    "TE_FEATURES = [f\"te_{c}\" for c in TE_COLS]\n",
    "features = base + ORIG + TE_FEATURES\n",
    "\n",
    "X = train[features].copy()\n",
    "y = train[target].copy()\n",
    "X_test = test[features].copy()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(X.columns)\n",
    "print(X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7e12f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage_safe(df):\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.float64:\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "        elif df[col].dtype == np.int64:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fef3db34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:8.85098\n",
      "[200]\tvalidation_0-rmse:8.80050\n",
      "[400]\tvalidation_0-rmse:8.77889\n",
      "[600]\tvalidation_0-rmse:8.76239\n",
      "[800]\tvalidation_0-rmse:8.74938\n",
      "[1000]\tvalidation_0-rmse:8.73911\n",
      "[1200]\tvalidation_0-rmse:8.73109\n",
      "[1400]\tvalidation_0-rmse:8.72459\n",
      "[1600]\tvalidation_0-rmse:8.71889\n",
      "[1800]\tvalidation_0-rmse:8.71331\n",
      "[2000]\tvalidation_0-rmse:8.70866\n",
      "[2200]\tvalidation_0-rmse:8.70480\n",
      "[2400]\tvalidation_0-rmse:8.70153\n",
      "[2600]\tvalidation_0-rmse:8.69874\n",
      "[2800]\tvalidation_0-rmse:8.69576\n",
      "[2999]\tvalidation_0-rmse:8.69394\n",
      "Fold 1 RMSE: 8.69363\n",
      "[0]\tvalidation_0-rmse:8.85333\n",
      "[200]\tvalidation_0-rmse:8.80530\n",
      "[400]\tvalidation_0-rmse:8.78453\n",
      "[600]\tvalidation_0-rmse:8.76797\n",
      "[800]\tvalidation_0-rmse:8.75463\n",
      "[1000]\tvalidation_0-rmse:8.74425\n",
      "[1200]\tvalidation_0-rmse:8.73550\n",
      "[1400]\tvalidation_0-rmse:8.72817\n",
      "[1600]\tvalidation_0-rmse:8.72140\n",
      "[1800]\tvalidation_0-rmse:8.71598\n",
      "[2000]\tvalidation_0-rmse:8.71163\n",
      "[2200]\tvalidation_0-rmse:8.70799\n",
      "[2400]\tvalidation_0-rmse:8.70445\n",
      "[2600]\tvalidation_0-rmse:8.70129\n",
      "[2800]\tvalidation_0-rmse:8.69817\n",
      "[2999]\tvalidation_0-rmse:8.69599\n",
      "Fold 2 RMSE: 8.69564\n",
      "[0]\tvalidation_0-rmse:8.84562\n",
      "[200]\tvalidation_0-rmse:8.79726\n",
      "[400]\tvalidation_0-rmse:8.77490\n",
      "[600]\tvalidation_0-rmse:8.75705\n",
      "[800]\tvalidation_0-rmse:8.74421\n",
      "[1000]\tvalidation_0-rmse:8.73319\n",
      "[1200]\tvalidation_0-rmse:8.72540\n",
      "[1400]\tvalidation_0-rmse:8.71776\n",
      "[1600]\tvalidation_0-rmse:8.71081\n",
      "[1800]\tvalidation_0-rmse:8.70518\n",
      "[2000]\tvalidation_0-rmse:8.70042\n",
      "[2200]\tvalidation_0-rmse:8.69614\n",
      "[2400]\tvalidation_0-rmse:8.69254\n",
      "[2600]\tvalidation_0-rmse:8.68943\n",
      "[2800]\tvalidation_0-rmse:8.68656\n",
      "[2999]\tvalidation_0-rmse:8.68422\n",
      "Fold 3 RMSE: 8.68391\n",
      "[0]\tvalidation_0-rmse:8.86313\n",
      "[200]\tvalidation_0-rmse:8.81617\n",
      "[400]\tvalidation_0-rmse:8.79265\n",
      "[600]\tvalidation_0-rmse:8.77644\n",
      "[800]\tvalidation_0-rmse:8.76344\n",
      "[1000]\tvalidation_0-rmse:8.75288\n",
      "[1200]\tvalidation_0-rmse:8.74433\n",
      "[1400]\tvalidation_0-rmse:8.73655\n",
      "[1600]\tvalidation_0-rmse:8.73000\n",
      "[1800]\tvalidation_0-rmse:8.72480\n",
      "[2000]\tvalidation_0-rmse:8.72066\n",
      "[2200]\tvalidation_0-rmse:8.71613\n",
      "[2400]\tvalidation_0-rmse:8.71257\n",
      "[2600]\tvalidation_0-rmse:8.70883\n",
      "[2800]\tvalidation_0-rmse:8.70581\n",
      "[2999]\tvalidation_0-rmse:8.70313\n",
      "Fold 4 RMSE: 8.70279\n",
      "[0]\tvalidation_0-rmse:8.87349\n",
      "[200]\tvalidation_0-rmse:8.82590\n",
      "[400]\tvalidation_0-rmse:8.80336\n",
      "[600]\tvalidation_0-rmse:8.78812\n",
      "[800]\tvalidation_0-rmse:8.77604\n",
      "[1000]\tvalidation_0-rmse:8.76567\n",
      "[1200]\tvalidation_0-rmse:8.75744\n",
      "[1400]\tvalidation_0-rmse:8.75033\n",
      "[1600]\tvalidation_0-rmse:8.74454\n",
      "[1800]\tvalidation_0-rmse:8.73944\n",
      "[2000]\tvalidation_0-rmse:8.73472\n",
      "[2200]\tvalidation_0-rmse:8.73070\n",
      "[2400]\tvalidation_0-rmse:8.72710\n",
      "[2600]\tvalidation_0-rmse:8.72415\n",
      "[2800]\tvalidation_0-rmse:8.72163\n",
      "[2999]\tvalidation_0-rmse:8.71950\n",
      "Fold 5 RMSE: 8.71909\n",
      "------------------------------\n",
      "OOF RMSE: 8.69902\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# =========================\n",
    "# 改良ポイント（過小予測の解消を優先）\n",
    "# 1) 線形予測値（lin_pred）を残差モデルの特徴量に追加（超効く）\n",
    "# 2) 高得点側に重みを付けて学習（過小予測を減らす）\n",
    "# 3) 最終予測を y の範囲にクリップ（破綻防止）\n",
    "# =========================\n",
    "\n",
    "# カラム型\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "oof_linear = np.zeros(len(X))\n",
    "oof_resid  = np.zeros(len(X))\n",
    "test_linear_folds = []\n",
    "test_resid_folds  = []\n",
    "\n",
    "linear_model = Pipeline(steps=[\n",
    "    (\"pre\", ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )),\n",
    "    (\"ridge\", Ridge(alpha=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "xgb_params = dict(\n",
    "    n_estimators=3000,          # 探索しやすいように少し軽く\n",
    "    learning_rate=0.03,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=5,         # 過学習しづらく、安定しやすい\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"rmse\",\n",
    "    early_stopping_rounds=100,\n",
    "    tree_method=\"hist\",         # GPUなら \"gpu_hist\" に\n",
    ")\n",
    "\n",
    "def factorize_fit_transform(train_df, val_df, test_df, cat_cols):\n",
    "    train_df = train_df.copy()\n",
    "    val_df   = val_df.copy()\n",
    "    test_df  = test_df.copy()\n",
    "    for c in cat_cols:\n",
    "        comb = pd.concat([train_df[c], val_df[c], test_df[c]], axis=0)\n",
    "        codes, _ = comb.factorize(sort=True)\n",
    "        n_tr = len(train_df)\n",
    "        n_va = len(val_df)\n",
    "        train_df[c] = codes[:n_tr]\n",
    "        val_df[c]   = codes[n_tr:n_tr+n_va]\n",
    "        test_df[c]  = codes[n_tr+n_va:]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def reduce_mem_usage_safe(df):\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.float64:\n",
    "            df[col] = df[col].astype(np.float32)\n",
    "        elif df[col].dtype == np.int64:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "    return df\n",
    "\n",
    "y_min, y_max = y.min(), y.max()\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(X, y), 1):\n",
    "    X_tr, y_tr = X.iloc[tr_idx].copy(), y.iloc[tr_idx].copy()\n",
    "    X_va, y_va = X.iloc[va_idx].copy(), y.iloc[va_idx].copy()\n",
    "\n",
    "    # ---- (A) 線形 ----\n",
    "    linear_model.fit(X_tr, y_tr)\n",
    "\n",
    "    pred_lin_tr = linear_model.predict(X_tr)\n",
    "    pred_lin_va = linear_model.predict(X_va)\n",
    "    pred_lin_te = linear_model.predict(X_test)\n",
    "\n",
    "    oof_linear[va_idx] = pred_lin_va\n",
    "    test_linear_folds.append(pred_lin_te)\n",
    "\n",
    "    # ---- (B) 残差 ----\n",
    "    resid_tr = y_tr - pred_lin_tr\n",
    "    resid_va_true = y_va - pred_lin_va\n",
    "\n",
    "    # ---- (C) 残差モデル入力 ----\n",
    "    X_tr2, X_va2, X_te2 = factorize_fit_transform(X_tr, X_va, X_test, cat_cols)\n",
    "\n",
    "    #★★★ ここに入れる ★★★\n",
    "    X_tr2[\"dist_to_max\"] = (100 - pred_lin_tr).clip(0).astype(np.float32)\n",
    "    X_va2[\"dist_to_max\"] = (100 - pred_lin_va).clip(0).astype(np.float32)\n",
    "    X_te2[\"dist_to_max\"] = (100 - pred_lin_te).clip(0).astype(np.float32)\n",
    "    \n",
    "    LOW = float(y.min())  # まずこれでOK。仮説値(19.6)を使うのは後で  \n",
    "    X_tr2[\"dist_to_min\"] = np.clip(pred_lin_tr - LOW, 0, None).astype(np.float32)\n",
    "    X_va2[\"dist_to_min\"] = np.clip(pred_lin_va - LOW, 0, None).astype(np.float32)\n",
    "    X_te2[\"dist_to_min\"] = np.clip(pred_lin_te - LOW, 0, None).astype(np.float32)\n",
    "\n",
    "    # ★ lin_pred を追加（過小予測を直す最優先の一手）\n",
    "    X_tr2[\"lin_pred\"] = pred_lin_tr.astype(np.float32)\n",
    "    X_va2[\"lin_pred\"] = pred_lin_va.astype(np.float32)\n",
    "    X_te2[\"lin_pred\"] = pred_lin_te.astype(np.float32)\n",
    "\n",
    "    # 軽量化\n",
    "    X_tr2 = reduce_mem_usage_safe(X_tr2)\n",
    "    X_va2 = reduce_mem_usage_safe(X_va2)\n",
    "    X_te2 = reduce_mem_usage_safe(X_te2)\n",
    "\n",
    "    # ★ 高得点側を重視（過小予測を減らす）\n",
    "    # 1〜2程度の軽い重み（極端にしない）\n",
    "    w_tr = (1.0 + (y_tr / y_tr.max())).astype(np.float32)\n",
    "    w_va = (1.0 + (y_va / y_tr.max())).astype(np.float32)  # eval用の重み（任意）\n",
    "\n",
    "    resid_model = XGBRegressor(**xgb_params)\n",
    "    resid_model.fit(\n",
    "        X_tr2, resid_tr,\n",
    "        sample_weight=w_tr,\n",
    "        eval_set=[(X_va2, resid_va_true)],\n",
    "        verbose=200\n",
    "    )\n",
    "\n",
    "    pred_resid_va = resid_model.predict(X_va2)\n",
    "    pred_resid_te = resid_model.predict(X_te2)\n",
    "\n",
    "    oof_resid[va_idx] = pred_resid_va\n",
    "    test_resid_folds.append(pred_resid_te)\n",
    "\n",
    "    # ---- (D) 合成 + クリップ ----\n",
    "    pred_final_va = pred_lin_va + pred_resid_va\n",
    "    pred_final_va = np.clip(pred_final_va, y_min, y_max)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_va, pred_final_va))\n",
    "    print(f\"Fold {fold} RMSE: {rmse:.5f}\")\n",
    "\n",
    "oof_final = oof_linear + oof_resid\n",
    "oof_final = np.clip(oof_final, y_min, y_max)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"OOF RMSE: {np.sqrt(mean_squared_error(y, oof_final)):.5f}\")\n",
    "\n",
    "test_linear = np.mean(np.vstack(test_linear_folds), axis=0)\n",
    "test_resid  = np.mean(np.vstack(test_resid_folds), axis=0)\n",
    "test_pred   = test_linear + test_resid\n",
    "test_pred   = np.clip(test_pred, y_min, y_max)\n",
    "\n",
    "# submission（必要なら）\n",
    "# sub = pd.DataFrame({\"id\": test[\"id\"], \"exam_score\": test_pred})\n",
    "# sub.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46f89f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630000</td>\n",
       "      <td>71.368789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630001</td>\n",
       "      <td>69.648101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630002</td>\n",
       "      <td>89.487619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630003</td>\n",
       "      <td>55.742865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630004</td>\n",
       "      <td>46.082344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  exam_score\n",
       "0  630000   71.368789\n",
       "1  630001   69.648101\n",
       "2  630002   89.487619\n",
       "3  630003   55.742865\n",
       "4  630004   46.082344"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission 作成（id列は自動で推定して作る）\n",
    "pred_col = target  # 'exam_score'\n",
    "\n",
    "# id列名を推定\n",
    "id_col = \"id\" if \"id\" in test.columns else (\"Id\" if \"Id\" in test.columns else None)\n",
    "if id_col is None:\n",
    "    raise ValueError(\"testに id / Id 列が見つかりません。id列名を手動で指定してください。\")\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    id_col: test[id_col].values,\n",
    "    pred_col: test_pred  # 直前で作った最終予測（線形 + 残差）\n",
    "})\n",
    "\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87059ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top residual samples shape: (100, 43)\n",
      "            y       pred      resid  abs_resid\n",
      "553891  100.0  52.207457  47.792543  47.792543\n",
      "78392   100.0  54.239219  45.760781  45.760781\n",
      "428160   72.6  29.026905  43.573095  43.573095\n",
      "526766   93.6  50.835317  42.764683  42.764683\n",
      "613957   92.9  50.293985  42.606015  42.606015\n",
      "\n",
      "================================================================================\n",
      "① カテゴリ偏りチェック（Top100の上位頻出カテゴリ）\n",
      "================================================================================\n",
      "\n",
      "[gender] Top5\n",
      "gender\n",
      "male      37\n",
      "other     35\n",
      "female    28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[course] Top5\n",
      "course\n",
      "b.tech    22\n",
      "b.com     20\n",
      "bca       18\n",
      "bba       14\n",
      "b.sc      12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[internet_access] Top5\n",
      "internet_access\n",
      "yes    96\n",
      "no      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[sleep_quality] Top5\n",
      "sleep_quality\n",
      "poor       35\n",
      "average    33\n",
      "good       32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[study_method] Top5\n",
      "study_method\n",
      "coaching         25\n",
      "online videos    23\n",
      "self-study       23\n",
      "mixed            19\n",
      "group study      10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[facility_rating] Top5\n",
      "facility_rating\n",
      "high      43\n",
      "medium    34\n",
      "low       23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[exam_difficulty] Top5\n",
      "exam_difficulty\n",
      "moderate    67\n",
      "easy        23\n",
      "hard        10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "①-追加: Top100と全体の比率差（上位カテゴリ）\n",
      "================================================================================\n",
      "\n",
      "[gender] Top100比率 - 全体比率 (Top5)\n",
      "gender\n",
      "male      0.035725\n",
      "other     0.014925\n",
      "female   -0.050651\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "[course] Top100比率 - 全体比率 (Top5)\n",
      "course\n",
      "bca        0.039173\n",
      "b.com      0.023917\n",
      "diploma    0.020756\n",
      "bba        0.019930\n",
      "b.tech     0.011689\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "[internet_access] Top100比率 - 全体比率 (Top5)\n",
      "internet_access\n",
      "yes    0.040281\n",
      "no    -0.040281\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "[sleep_quality] Top100比率 - 全体比率 (Top5)\n",
      "sleep_quality\n",
      "poor       0.010833\n",
      "average    0.007403\n",
      "good      -0.018237\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "[study_method] Top100比率 - 全体比率 (Top5)\n",
      "study_method\n",
      "coaching         0.040957\n",
      "online videos    0.037814\n",
      "self-study       0.021856\n",
      "mixed           -0.005375\n",
      "group study     -0.095252\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "[facility_rating] Top100比率 - 全体比率 (Top5)\n",
      "facility_rating\n",
      "high      0.106921\n",
      "medium    0.000187\n",
      "low      -0.107108\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "[exam_difficulty] Top100比率 - 全体比率 (Top5)\n",
      "exam_difficulty\n",
      "moderate    0.108124\n",
      "easy       -0.050222\n",
      "hard       -0.057902\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "② 残差の符号偏り（過小/過大）\n",
      "================================================================================\n",
      "Top100 resid describe:\n",
      "count    100.000000\n",
      "mean       2.722863\n",
      "std       37.359204\n",
      "min      -41.541762\n",
      "25%      -36.014365\n",
      "50%       34.588019\n",
      "75%       36.668882\n",
      "max       47.792543\n",
      "Name: resid, dtype: float64\n",
      "\n",
      "Top100 resid sign count:  +:53, -:47, 0:0\n",
      "Top100 resid sign ratio:  +:53.00%, -:47.00%, 0:0.00%\n",
      "\n",
      "過小評価（residが大きい）Top10\n",
      "            y       pred      resid  abs_resid\n",
      "553891  100.0  52.207457  47.792543  47.792543\n",
      "78392   100.0  54.239219  45.760781  45.760781\n",
      "428160   72.6  29.026905  43.573095  43.573095\n",
      "526766   93.6  50.835317  42.764683  42.764683\n",
      "613957   92.9  50.293985  42.606015  42.606015\n",
      "47775    88.8  46.875039  41.924961  41.924961\n",
      "51537   100.0  58.381594  41.618406  41.618406\n",
      "93901    93.0  51.647755  41.352245  41.352245\n",
      "87444   100.0  58.896557  41.103443  41.103443\n",
      "538911   82.2  41.820815  40.379185  40.379185\n",
      "\n",
      "過大評価（residが小さい）Top10\n",
      "             y       pred      resid  abs_resid\n",
      "304834  21.000  62.541762 -41.541762  41.541762\n",
      "288715  30.200  71.486446 -41.286446  41.286446\n",
      "199720  19.599  60.169141 -40.570141  40.570141\n",
      "31253   21.100  61.432588 -40.332588  40.332588\n",
      "366570  30.200  69.838916 -39.638916  39.638916\n",
      "243180  23.600  63.215951 -39.615951  39.615951\n",
      "51409   19.900  58.632930 -38.732930  38.732930\n",
      "410018  26.600  64.794051 -38.194051  38.194051\n",
      "340684  25.200  63.268942 -38.068942  38.068942\n",
      "150111  19.599  57.627766 -38.028766  38.028766\n",
      "\n",
      "================================================================================\n",
      "③ ORIG特徴量の極端さチェック\n",
      "================================================================================\n",
      "\n",
      "Top100平均 - 全体平均（差が大きい順 Top20）\n",
      "orig_count_internet_access    562.966590\n",
      "orig_count_exam_difficulty    529.126105\n",
      "orig_count_study_method        13.809625\n",
      "orig_count_study_hours         11.687270\n",
      "orig_count_gender               6.338179\n",
      "orig_count_age                  3.648332\n",
      "orig_count_sleep_quality        1.291905\n",
      "orig_mean_facility_rating       0.810344\n",
      "orig_count_sleep_hours          0.534303\n",
      "orig_mean_class_attendance      0.449266\n",
      "orig_mean_study_method          0.213242\n",
      "orig_mean_sleep_hours           0.064569\n",
      "orig_mean_course                0.013913\n",
      "orig_mean_exam_difficulty       0.003484\n",
      "orig_mean_gender               -0.006912\n",
      "orig_mean_age                  -0.014203\n",
      "orig_mean_internet_access      -0.016666\n",
      "orig_mean_sleep_quality        -0.134009\n",
      "orig_mean_study_hours          -3.139222\n",
      "orig_count_course              -3.297273\n",
      "Name: mean, dtype: float64\n",
      "\n",
      "countが小さいのに mean が極端そう（候補 Top20）\n",
      "        orig_mean_age  orig_count_age  abs_mean_dev                      m  \\\n",
      "75322             NaN             NaN     24.240696  orig_mean_study_hours   \n",
      "554198            NaN             NaN     23.663550  orig_mean_study_hours   \n",
      "496134            NaN             NaN     23.663550  orig_mean_study_hours   \n",
      "80445             NaN             NaN     23.192491  orig_mean_study_hours   \n",
      "572316            NaN             NaN     23.192491  orig_mean_study_hours   \n",
      "597083            NaN             NaN     23.192491  orig_mean_study_hours   \n",
      "75952             NaN             NaN     23.192491  orig_mean_study_hours   \n",
      "451330            NaN             NaN     23.192491  orig_mean_study_hours   \n",
      "43197             NaN             NaN     23.192491  orig_mean_study_hours   \n",
      "613957            NaN             NaN     23.192491  orig_mean_study_hours   \n",
      "479255            NaN             NaN     23.192491  orig_mean_study_hours   \n",
      "428160            NaN             NaN     23.192491  orig_mean_study_hours   \n",
      "590151            NaN             NaN     22.753372  orig_mean_study_hours   \n",
      "516795            NaN             NaN     22.229691  orig_mean_study_hours   \n",
      "51537             NaN             NaN     21.829490  orig_mean_study_hours   \n",
      "293431            NaN             NaN     21.819134  orig_mean_study_hours   \n",
      "505456            NaN             NaN     21.812922  orig_mean_study_hours   \n",
      "322059            NaN             NaN     21.630792  orig_mean_study_hours   \n",
      "314728            NaN             NaN     20.798591  orig_mean_study_hours   \n",
      "26704             NaN             NaN     20.741154  orig_mean_study_hours   \n",
      "\n",
      "                           cnt  orig_mean_gender  orig_count_gender  \\\n",
      "75322   orig_count_study_hours               NaN                NaN   \n",
      "554198  orig_count_study_hours               NaN                NaN   \n",
      "496134  orig_count_study_hours               NaN                NaN   \n",
      "80445   orig_count_study_hours               NaN                NaN   \n",
      "572316  orig_count_study_hours               NaN                NaN   \n",
      "597083  orig_count_study_hours               NaN                NaN   \n",
      "75952   orig_count_study_hours               NaN                NaN   \n",
      "451330  orig_count_study_hours               NaN                NaN   \n",
      "43197   orig_count_study_hours               NaN                NaN   \n",
      "613957  orig_count_study_hours               NaN                NaN   \n",
      "479255  orig_count_study_hours               NaN                NaN   \n",
      "428160  orig_count_study_hours               NaN                NaN   \n",
      "590151  orig_count_study_hours               NaN                NaN   \n",
      "516795  orig_count_study_hours               NaN                NaN   \n",
      "51537   orig_count_study_hours               NaN                NaN   \n",
      "293431  orig_count_study_hours               NaN                NaN   \n",
      "505456  orig_count_study_hours               NaN                NaN   \n",
      "322059  orig_count_study_hours               NaN                NaN   \n",
      "314728  orig_count_study_hours               NaN                NaN   \n",
      "26704   orig_count_study_hours               NaN                NaN   \n",
      "\n",
      "        orig_mean_course  orig_count_course  orig_mean_study_hours  ...  \\\n",
      "75322                NaN                NaN              86.747368  ...   \n",
      "554198               NaN                NaN              86.170222  ...   \n",
      "496134               NaN                NaN              86.170222  ...   \n",
      "80445                NaN                NaN              39.314181  ...   \n",
      "572316               NaN                NaN              39.314181  ...   \n",
      "597083               NaN                NaN              39.314181  ...   \n",
      "75952                NaN                NaN              39.314181  ...   \n",
      "451330               NaN                NaN              39.314181  ...   \n",
      "43197                NaN                NaN              39.314181  ...   \n",
      "613957               NaN                NaN              39.314181  ...   \n",
      "479255               NaN                NaN              39.314181  ...   \n",
      "428160               NaN                NaN              39.314181  ...   \n",
      "590151               NaN                NaN              39.753300  ...   \n",
      "516795               NaN                NaN              84.736364  ...   \n",
      "51537                NaN                NaN              40.677182  ...   \n",
      "293431               NaN                NaN              84.325806  ...   \n",
      "505456               NaN                NaN              40.693750  ...   \n",
      "322059               NaN                NaN              40.875880  ...   \n",
      "314728               NaN                NaN              83.305263  ...   \n",
      "26704                NaN                NaN              83.247826  ...   \n",
      "\n",
      "        orig_mean_sleep_hours  orig_count_sleep_hours  \\\n",
      "75322                     NaN                     NaN   \n",
      "554198                    NaN                     NaN   \n",
      "496134                    NaN                     NaN   \n",
      "80445                     NaN                     NaN   \n",
      "572316                    NaN                     NaN   \n",
      "597083                    NaN                     NaN   \n",
      "75952                     NaN                     NaN   \n",
      "451330                    NaN                     NaN   \n",
      "43197                     NaN                     NaN   \n",
      "613957                    NaN                     NaN   \n",
      "479255                    NaN                     NaN   \n",
      "428160                    NaN                     NaN   \n",
      "590151                    NaN                     NaN   \n",
      "516795                    NaN                     NaN   \n",
      "51537                     NaN                     NaN   \n",
      "293431                    NaN                     NaN   \n",
      "505456                    NaN                     NaN   \n",
      "322059                    NaN                     NaN   \n",
      "314728                    NaN                     NaN   \n",
      "26704                     NaN                     NaN   \n",
      "\n",
      "        orig_mean_sleep_quality  orig_count_sleep_quality  \\\n",
      "75322                       NaN                       NaN   \n",
      "554198                      NaN                       NaN   \n",
      "496134                      NaN                       NaN   \n",
      "80445                       NaN                       NaN   \n",
      "572316                      NaN                       NaN   \n",
      "597083                      NaN                       NaN   \n",
      "75952                       NaN                       NaN   \n",
      "451330                      NaN                       NaN   \n",
      "43197                       NaN                       NaN   \n",
      "613957                      NaN                       NaN   \n",
      "479255                      NaN                       NaN   \n",
      "428160                      NaN                       NaN   \n",
      "590151                      NaN                       NaN   \n",
      "516795                      NaN                       NaN   \n",
      "51537                       NaN                       NaN   \n",
      "293431                      NaN                       NaN   \n",
      "505456                      NaN                       NaN   \n",
      "322059                      NaN                       NaN   \n",
      "314728                      NaN                       NaN   \n",
      "26704                       NaN                       NaN   \n",
      "\n",
      "        orig_mean_study_method  orig_count_study_method  \\\n",
      "75322                      NaN                      NaN   \n",
      "554198                     NaN                      NaN   \n",
      "496134                     NaN                      NaN   \n",
      "80445                      NaN                      NaN   \n",
      "572316                     NaN                      NaN   \n",
      "597083                     NaN                      NaN   \n",
      "75952                      NaN                      NaN   \n",
      "451330                     NaN                      NaN   \n",
      "43197                      NaN                      NaN   \n",
      "613957                     NaN                      NaN   \n",
      "479255                     NaN                      NaN   \n",
      "428160                     NaN                      NaN   \n",
      "590151                     NaN                      NaN   \n",
      "516795                     NaN                      NaN   \n",
      "51537                      NaN                      NaN   \n",
      "293431                     NaN                      NaN   \n",
      "505456                     NaN                      NaN   \n",
      "322059                     NaN                      NaN   \n",
      "314728                     NaN                      NaN   \n",
      "26704                      NaN                      NaN   \n",
      "\n",
      "        orig_mean_facility_rating  orig_count_facility_rating  \\\n",
      "75322                         NaN                         NaN   \n",
      "554198                        NaN                         NaN   \n",
      "496134                        NaN                         NaN   \n",
      "80445                         NaN                         NaN   \n",
      "572316                        NaN                         NaN   \n",
      "597083                        NaN                         NaN   \n",
      "75952                         NaN                         NaN   \n",
      "451330                        NaN                         NaN   \n",
      "43197                         NaN                         NaN   \n",
      "613957                        NaN                         NaN   \n",
      "479255                        NaN                         NaN   \n",
      "428160                        NaN                         NaN   \n",
      "590151                        NaN                         NaN   \n",
      "516795                        NaN                         NaN   \n",
      "51537                         NaN                         NaN   \n",
      "293431                        NaN                         NaN   \n",
      "505456                        NaN                         NaN   \n",
      "322059                        NaN                         NaN   \n",
      "314728                        NaN                         NaN   \n",
      "26704                         NaN                         NaN   \n",
      "\n",
      "        orig_mean_exam_difficulty  orig_count_exam_difficulty  \n",
      "75322                         NaN                         NaN  \n",
      "554198                        NaN                         NaN  \n",
      "496134                        NaN                         NaN  \n",
      "80445                         NaN                         NaN  \n",
      "572316                        NaN                         NaN  \n",
      "597083                        NaN                         NaN  \n",
      "75952                         NaN                         NaN  \n",
      "451330                        NaN                         NaN  \n",
      "43197                         NaN                         NaN  \n",
      "613957                        NaN                         NaN  \n",
      "479255                        NaN                         NaN  \n",
      "428160                        NaN                         NaN  \n",
      "590151                        NaN                         NaN  \n",
      "516795                        NaN                         NaN  \n",
      "51537                         NaN                         NaN  \n",
      "293431                        NaN                         NaN  \n",
      "505456                        NaN                         NaN  \n",
      "322059                        NaN                         NaN  \n",
      "314728                        NaN                         NaN  \n",
      "26704                         NaN                         NaN  \n",
      "\n",
      "[20 rows x 25 columns]\n",
      "\n",
      "================================================================================\n",
      "④ 数値特徴量のスケール外れチェック（Top100 vs 全体）\n",
      "================================================================================\n",
      "\n",
      "Top100平均との差が大きい数値列（| (TopMean - AllMean)/AllStd | 上位20）\n",
      "orig_count_study_hours         0.298802\n",
      "orig_mean_facility_rating      0.262738\n",
      "te_facility_rating             0.262631\n",
      "study_hours                    0.237019\n",
      "orig_count_exam_difficulty     0.225815\n",
      "orig_mean_study_hours          0.220997\n",
      "te_course                      0.192901\n",
      "orig_count_study_method        0.180300\n",
      "orig_mean_internet_access      0.148240\n",
      "orig_count_internet_access     0.148240\n",
      "orig_count_class_attendance    0.120275\n",
      "orig_count_gender              0.100353\n",
      "te_exam_difficulty             0.099333\n",
      "orig_count_course              0.089044\n",
      "orig_count_age                 0.087055\n",
      "class_attendance               0.083748\n",
      "orig_mean_gender               0.083738\n",
      "orig_mean_age                  0.072428\n",
      "orig_mean_class_attendance     0.067716\n",
      "orig_mean_study_method         0.059792\n",
      "dtype: float64\n",
      "\n",
      "Top100が全体レンジの端っこに寄ってそうな列（max_gap上位20）\n",
      "                                top_min      all_min      top_max  \\\n",
      "orig_mean_class_attendance    49.354690    45.506030    77.082759   \n",
      "orig_mean_study_hours         39.314181    35.915308    86.747368   \n",
      "class_attendance              40.600000    40.600000    99.300000   \n",
      "age                           17.000000    17.000000    24.000000   \n",
      "orig_mean_exam_difficulty     62.383022    62.383022    62.629580   \n",
      "orig_mean_study_method        58.729919    58.729919    68.550963   \n",
      "orig_count_study_method     3894.000000  3894.000000  4079.000000   \n",
      "orig_mean_facility_rating     58.594346    58.594346    66.165916   \n",
      "orig_count_facility_rating  6602.000000  6602.000000  6760.000000   \n",
      "orig_count_exam_difficulty  3981.000000  3981.000000  9878.000000   \n",
      "orig_mean_sleep_quality       57.917582    57.917582    67.138598   \n",
      "te_gender                     62.147368    62.147368    62.798221   \n",
      "te_course                     61.859529    61.859529    63.289417   \n",
      "te_sleep_quality              56.985186    56.985186    67.918907   \n",
      "te_study_method               57.655861    57.655861    69.278746   \n",
      "te_facility_rating            57.924199    57.924199    66.722258   \n",
      "orig_count_sleep_quality    6619.000000  6619.000000  6694.000000   \n",
      "orig_mean_sleep_hours         56.418237    56.418237    67.557936   \n",
      "orig_count_sleep_hours       300.000000     0.000000   515.000000   \n",
      "study_hours                    0.080000     0.080000     7.910000   \n",
      "\n",
      "                                all_max     min_gap   max_gap  \n",
      "orig_mean_class_attendance    81.161290    3.848660  4.078532  \n",
      "orig_mean_study_hours         89.389474    3.398873  2.642105  \n",
      "class_attendance              99.400000    0.000000  0.100000  \n",
      "age                           24.000000    0.000000  0.000000  \n",
      "orig_mean_exam_difficulty     62.629580    0.000000  0.000000  \n",
      "orig_mean_study_method        68.550963    0.000000  0.000000  \n",
      "orig_count_study_method     4079.000000    0.000000  0.000000  \n",
      "orig_mean_facility_rating     66.165916    0.000000  0.000000  \n",
      "orig_count_facility_rating  6760.000000    0.000000  0.000000  \n",
      "orig_count_exam_difficulty  9878.000000    0.000000  0.000000  \n",
      "orig_mean_sleep_quality       67.138598    0.000000  0.000000  \n",
      "te_gender                     62.798221    0.000000  0.000000  \n",
      "te_course                     63.289417    0.000000  0.000000  \n",
      "te_sleep_quality              67.918907    0.000000  0.000000  \n",
      "te_study_method               69.278746    0.000000  0.000000  \n",
      "te_facility_rating            66.722258    0.000000  0.000000  \n",
      "orig_count_sleep_quality    6694.000000    0.000000  0.000000  \n",
      "orig_mean_sleep_hours         67.557936    0.000000  0.000000  \n",
      "orig_count_sleep_hours       515.000000  300.000000  0.000000  \n",
      "study_hours                    7.910000    0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 前提：\n",
    "# - train, test, X, y, X_test がある\n",
    "# - oof_linear がある（線形モデルのOOF予測）\n",
    "#   ※もし最終OOF(oof_final)で見たいなら、oof_linear を oof_final に置換\n",
    "# - ORIG: ORIG特徴量名リスト（例: [\"orig_mean_x\", \"orig_count_x\", ...]）\n",
    "# - base: 元の特徴量名リスト\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 0) 残差上位100件を作る\n",
    "resid = y - pd.Series(oof_linear, index=y.index)\n",
    "resid_abs = resid.abs()\n",
    "\n",
    "topN = 100\n",
    "top_idx = resid_abs.sort_values(ascending=False).head(topN).index\n",
    "\n",
    "# X は特徴量DF（trainのfeaturesだけにしてある想定）\n",
    "top = X.loc[top_idx].copy()\n",
    "top[\"y\"] = y.loc[top_idx]\n",
    "top[\"pred\"] = pd.Series(oof_linear, index=y.index).loc[top_idx]\n",
    "top[\"resid\"] = resid.loc[top_idx]\n",
    "top[\"abs_resid\"] = resid_abs.loc[top_idx]\n",
    "\n",
    "print(\"Top residual samples shape:\", top.shape)\n",
    "print(top[[\"y\", \"pred\", \"resid\", \"abs_resid\"]].head())\n",
    "\n",
    "\n",
    "# 1) ① 特定カテゴリに偏っていないか\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"① カテゴリ偏りチェック（Top100の上位頻出カテゴリ）\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for c in cat_cols:\n",
    "    print(f\"\\n[{c}] Top5\")\n",
    "    print(top[c].value_counts(dropna=False).head(5))\n",
    "\n",
    "# 追加：全体との差を見たい場合（Top100比率 - 全体比率）\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"①-追加: Top100と全体の比率差（上位カテゴリ）\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for c in cat_cols:\n",
    "    top_ratio = top[c].value_counts(normalize=True, dropna=False)\n",
    "    all_ratio = X[c].value_counts(normalize=True, dropna=False)\n",
    "    diff = (top_ratio - all_ratio).sort_values(ascending=False).head(5)\n",
    "    print(f\"\\n[{c}] Top100比率 - 全体比率 (Top5)\")\n",
    "    print(diff)\n",
    "\n",
    "\n",
    "# 2) ② 予測が一方向に外れていないか（残差の符号の偏り）\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"② 残差の符号偏り（過小/過大）\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"Top100 resid describe:\")\n",
    "print(top[\"resid\"].describe())\n",
    "\n",
    "pos = (top[\"resid\"] > 0).sum()\n",
    "neg = (top[\"resid\"] < 0).sum()\n",
    "zero = (top[\"resid\"] == 0).sum()\n",
    "print(f\"\\nTop100 resid sign count:  +:{pos}, -:{neg}, 0:{zero}\")\n",
    "print(f\"Top100 resid sign ratio:  +:{pos/topN:.2%}, -:{neg/topN:.2%}, 0:{zero/topN:.2%}\")\n",
    "\n",
    "# 追加：残差の大きい順で「過小評価トップ」「過大評価トップ」\n",
    "print(\"\\n過小評価（residが大きい）Top10\")\n",
    "print(top.sort_values(\"resid\", ascending=False)[[\"y\",\"pred\",\"resid\",\"abs_resid\"]].head(10))\n",
    "\n",
    "print(\"\\n過大評価（residが小さい）Top10\")\n",
    "print(top.sort_values(\"resid\", ascending=True)[[\"y\",\"pred\",\"resid\",\"abs_resid\"]].head(10))\n",
    "\n",
    "\n",
    "# 3) ③ ORIG / TE が極端でないか（ORIG中心）\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"③ ORIG特徴量の極端さチェック\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ORIGが無い場合でも落ちないように\n",
    "orig_cols_in_X = [c for c in (ORIG if \"ORIG\" in globals() else []) if c in X.columns]\n",
    "\n",
    "if len(orig_cols_in_X) == 0:\n",
    "    print(\"ORIG特徴量が X に見つかりません（orig_cols_in_X が空）\")\n",
    "else:\n",
    "    # Top100の統計\n",
    "    top_desc = top[orig_cols_in_X].describe().T\n",
    "\n",
    "    # 全体の統計\n",
    "    all_desc = X[orig_cols_in_X].describe().T\n",
    "\n",
    "    # 差分（Top100平均 - 全体平均）\n",
    "    diff_mean = (top_desc[\"mean\"] - all_desc[\"mean\"]).sort_values(ascending=False)\n",
    "\n",
    "    print(\"\\nTop100平均 - 全体平均（差が大きい順 Top20）\")\n",
    "    print(diff_mean.head(20))\n",
    "\n",
    "    # count系が小さいのにmeanが極端な候補を探す\n",
    "    mean_cols = [c for c in orig_cols_in_X if \"orig_mean_\" in c]\n",
    "    cnt_cols  = [c for c in orig_cols_in_X if \"orig_count_\" in c]\n",
    "\n",
    "    if len(mean_cols) > 0 and len(cnt_cols) > 0:\n",
    "        # mean列に対応するcount列のペアを作る\n",
    "        pairs = []\n",
    "        for m in mean_cols:\n",
    "            base_name = m.replace(\"orig_mean_\", \"\")\n",
    "            cnt_name = f\"orig_count_{base_name}\"\n",
    "            if cnt_name in X.columns:\n",
    "                pairs.append((m, cnt_name))\n",
    "\n",
    "        if len(pairs) == 0:\n",
    "            print(\"\\n(mean,count)の対応ペアが見つかりませんでした。\")\n",
    "        else:\n",
    "            # 「countが小さいのにmeanが全体平均との差が大きい」行を探す\n",
    "            global_mean = y.mean()\n",
    "            rows = []\n",
    "            for m, cnt in pairs:\n",
    "                tmp = top[[m, cnt]].copy()\n",
    "                tmp[\"abs_mean_dev\"] = (tmp[m] - global_mean).abs()\n",
    "                tmp[\"m\"] = m\n",
    "                tmp[\"cnt\"] = cnt\n",
    "                rows.append(tmp)\n",
    "\n",
    "            chk = pd.concat(rows, axis=0)\n",
    "            chk = chk.sort_values([\"abs_mean_dev\",], ascending=False)\n",
    "\n",
    "            print(\"\\ncountが小さいのに mean が極端そう（候補 Top20）\")\n",
    "            # cnt列名が行ごとに違うので表示を揃える\n",
    "            print(chk.head(20))\n",
    "    else:\n",
    "        print(\"\\nmean_cols または cnt_cols が見つかりませんでした。\")\n",
    "\n",
    "\n",
    "# 4) ④ 数値特徴量のスケール外れ\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"④ 数値特徴量のスケール外れチェック（Top100 vs 全体）\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# Top100と全体で平均・標準偏差がズレてる列\n",
    "if len(num_cols) == 0:\n",
    "    print(\"数値列が見つかりません。\")\n",
    "else:\n",
    "    top_mu = top[num_cols].mean(numeric_only=True)\n",
    "    all_mu = X[num_cols].mean(numeric_only=True)\n",
    "    top_sd = top[num_cols].std(numeric_only=True).replace(0, np.nan)\n",
    "    all_sd = X[num_cols].std(numeric_only=True).replace(0, np.nan)\n",
    "\n",
    "    # z差分っぽい指標（Top100平均との差 / 全体std）\n",
    "    z_shift = ((top_mu - all_mu) / all_sd).abs().sort_values(ascending=False)\n",
    "\n",
    "    print(\"\\nTop100平均との差が大きい数値列（| (TopMean - AllMean)/AllStd | 上位20）\")\n",
    "    print(z_shift.head(20))\n",
    "\n",
    "    # Top100で極端な値が出ている列（max/min）\n",
    "    top_min = top[num_cols].min(numeric_only=True)\n",
    "    top_max = top[num_cols].max(numeric_only=True)\n",
    "    all_min = X[num_cols].min(numeric_only=True)\n",
    "    all_max = X[num_cols].max(numeric_only=True)\n",
    "\n",
    "    extreme = pd.DataFrame({\n",
    "        \"top_min\": top_min, \"all_min\": all_min,\n",
    "        \"top_max\": top_max, \"all_max\": all_max,\n",
    "    })\n",
    "\n",
    "    # 全体範囲に対してTop100が端に寄りすぎている列を上位表示（簡易）\n",
    "    extreme[\"min_gap\"] = (extreme[\"top_min\"] - extreme[\"all_min\"]).abs()\n",
    "    extreme[\"max_gap\"] = (extreme[\"top_max\"] - extreme[\"all_max\"]).abs()\n",
    "\n",
    "    print(\"\\nTop100が全体レンジの端っこに寄ってそうな列（max_gap上位20）\")\n",
    "    print(extreme.sort_values(\"max_gap\", ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61f46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
