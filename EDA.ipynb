{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "212db142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5526e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape: (630000, 13)\n",
      "test.shape: (270000, 12)\n",
      "orig.shape: (20000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>course</th>\n",
       "      <th>study_hours</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>internet_access</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>sleep_quality</th>\n",
       "      <th>study_method</th>\n",
       "      <th>facility_rating</th>\n",
       "      <th>exam_difficulty</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>male</td>\n",
       "      <td>diploma</td>\n",
       "      <td>2.78</td>\n",
       "      <td>92.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>7.4</td>\n",
       "      <td>poor</td>\n",
       "      <td>coaching</td>\n",
       "      <td>low</td>\n",
       "      <td>hard</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>other</td>\n",
       "      <td>bca</td>\n",
       "      <td>3.37</td>\n",
       "      <td>64.8</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.6</td>\n",
       "      <td>average</td>\n",
       "      <td>online videos</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>7.88</td>\n",
       "      <td>76.8</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.5</td>\n",
       "      <td>poor</td>\n",
       "      <td>coaching</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>90.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>other</td>\n",
       "      <td>diploma</td>\n",
       "      <td>0.67</td>\n",
       "      <td>48.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.8</td>\n",
       "      <td>average</td>\n",
       "      <td>online videos</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "      <td>29.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>diploma</td>\n",
       "      <td>0.89</td>\n",
       "      <td>71.6</td>\n",
       "      <td>yes</td>\n",
       "      <td>9.8</td>\n",
       "      <td>poor</td>\n",
       "      <td>coaching</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "      <td>43.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19997</td>\n",
       "      <td>18</td>\n",
       "      <td>other</td>\n",
       "      <td>bba</td>\n",
       "      <td>6.50</td>\n",
       "      <td>71.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>self-study</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "      <td>86.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19998</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>b.com</td>\n",
       "      <td>3.71</td>\n",
       "      <td>41.6</td>\n",
       "      <td>no</td>\n",
       "      <td>5.9</td>\n",
       "      <td>average</td>\n",
       "      <td>coaching</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "      <td>60.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19999</td>\n",
       "      <td>19</td>\n",
       "      <td>other</td>\n",
       "      <td>diploma</td>\n",
       "      <td>7.88</td>\n",
       "      <td>68.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.6</td>\n",
       "      <td>poor</td>\n",
       "      <td>group study</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "      <td>64.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>20000</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>bba</td>\n",
       "      <td>4.60</td>\n",
       "      <td>76.3</td>\n",
       "      <td>no</td>\n",
       "      <td>6.1</td>\n",
       "      <td>good</td>\n",
       "      <td>self-study</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>20001</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>7.50</td>\n",
       "      <td>47.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>7.5</td>\n",
       "      <td>poor</td>\n",
       "      <td>coaching</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       student_id  age  gender   course  study_hours  class_attendance  \\\n",
       "0               1   17    male  diploma         2.78              92.9   \n",
       "1               2   23   other      bca         3.37              64.8   \n",
       "2               3   22    male     b.sc         7.88              76.8   \n",
       "3               4   20   other  diploma         0.67              48.4   \n",
       "4               5   20  female  diploma         0.89              71.6   \n",
       "...           ...  ...     ...      ...          ...               ...   \n",
       "19995       19997   18   other      bba         6.50              71.3   \n",
       "19996       19998   18    male    b.com         3.71              41.6   \n",
       "19997       19999   19   other  diploma         7.88              68.2   \n",
       "19998       20000   19    male      bba         4.60              76.3   \n",
       "19999       20001   20    male     b.sc         7.50              47.9   \n",
       "\n",
       "      internet_access  sleep_hours sleep_quality   study_method  \\\n",
       "0                 yes          7.4          poor       coaching   \n",
       "1                 yes          4.6       average  online videos   \n",
       "2                 yes          8.5          poor       coaching   \n",
       "3                 yes          5.8       average  online videos   \n",
       "4                 yes          9.8          poor       coaching   \n",
       "...               ...          ...           ...            ...   \n",
       "19995             yes          5.0          good     self-study   \n",
       "19996              no          5.9       average       coaching   \n",
       "19997             yes          4.6          poor    group study   \n",
       "19998              no          6.1          good     self-study   \n",
       "19999             yes          7.5          poor       coaching   \n",
       "\n",
       "      facility_rating exam_difficulty  exam_score  \n",
       "0                 low            hard        58.9  \n",
       "1              medium        moderate        54.8  \n",
       "2                high        moderate        90.3  \n",
       "3                 low        moderate        29.7  \n",
       "4                 low        moderate        43.7  \n",
       "...               ...             ...         ...  \n",
       "19995             low            easy        86.5  \n",
       "19996          medium        moderate        60.9  \n",
       "19997             low            easy        64.5  \n",
       "19998          medium        moderate        79.0  \n",
       "19999          medium        moderate        71.0  \n",
       "\n",
       "[20000 rows x 13 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, gc\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "orig = pd.read_csv('Exam_Score_Prediction.csv')\n",
    "\n",
    "print(\"train_shape:\",train.shape)\n",
    "print(\"test.shape:\",test.shape)\n",
    "print(\"orig.shape:\",orig.shape)\n",
    "\n",
    "orig\n",
    "\n",
    "# 今後のためにリストを作る\n",
    "target = 'exam_score'\n",
    "base = [col for col in train.columns if col not in ['id', target]]\n",
    "categories = train.select_dtypes('object').columns.to_list()\n",
    "nums = [col for col in base if col not in categories]\n",
    "print(f'{len(base)} Base Features:{base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5970102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 ORIG Features Created.\n"
     ]
    }
   ],
   "source": [
    "ORIG = []\n",
    "\n",
    "# 外部データの各カラムのユニークごとの平均値というカラムを追加する。\n",
    "for col in base:\n",
    "    # 一つの列に対してgroupbyで固有の値をまとめる。それらのtargetをそれぞれ平均する\n",
    "    mean_map = orig.groupby(col)[target].mean() \n",
    "    new_mean_col_name = f\"orig_mean_{col}\"\n",
    "    mean_map.name = new_mean_col_name\n",
    "    \n",
    "    train = train.merge(mean_map, on=col, how='left') # colをキーにして\n",
    "    test = test.merge(mean_map, on=col, how='left')\n",
    "    ORIG.append(new_mean_col_name)\n",
    "    \n",
    "# 外部データの各カラムのユニークごとのサイズというカラムを追加する。\n",
    "    new_count_col_name = f\"orig_count_{col}\"\n",
    "    count_map = orig.groupby(col).size().reset_index(name=new_count_col_name)\n",
    "    \n",
    "    train = train.merge(count_map, on=col, how='left')\n",
    "    test = test.merge(count_map, on=col, how='left')\n",
    "    ORIG.append(new_count_col_name)\n",
    "\n",
    "print(f'{len(ORIG)} ORIG Features Created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8490d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origには存在するが、trainには存在しないカテゴリを全体平均で埋める\n",
    "for col in ORIG:\n",
    "    if 'mean' in col:\n",
    "        train[col] = train[col].fillna(orig[target].mean())\n",
    "        test[col] = test[col].fillna(orig[target].mean())\n",
    "    else:\n",
    "        train[col] = train[col].fillna(0)\n",
    "        test[col] = test[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3406c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce_mem_usage はここに定義（そのままでOK）\n",
    "\n",
    "features = base + ORIG\n",
    "\n",
    "# まず X, y を作る（これが先）\n",
    "X = train[features].copy()\n",
    "y = train[target].copy()\n",
    "\n",
    "# test側も、モデルに入れる列だけにそろえる（重要）\n",
    "X_test = test[features].copy()\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba7f5b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Encoding applied to 6 features.\n",
      "TE_COLS: ['gender', 'course', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n",
      "Index(['age', 'gender', 'course', 'study_hours', 'class_attendance',\n",
      "       'internet_access', 'sleep_hours', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty', 'orig_mean_age', 'orig_count_age',\n",
      "       'orig_mean_gender', 'orig_count_gender', 'orig_mean_course',\n",
      "       'orig_count_course', 'orig_mean_study_hours', 'orig_count_study_hours',\n",
      "       'orig_mean_class_attendance', 'orig_count_class_attendance',\n",
      "       'orig_mean_internet_access', 'orig_count_internet_access',\n",
      "       'orig_mean_sleep_hours', 'orig_count_sleep_hours',\n",
      "       'orig_mean_sleep_quality', 'orig_count_sleep_quality',\n",
      "       'orig_mean_study_method', 'orig_count_study_method',\n",
      "       'orig_mean_facility_rating', 'orig_count_facility_rating',\n",
      "       'orig_mean_exam_difficulty', 'orig_count_exam_difficulty', 'te_gender',\n",
      "       'te_course', 'te_sleep_quality', 'te_study_method',\n",
      "       'te_facility_rating', 'te_exam_difficulty'],\n",
      "      dtype='object')\n",
      "Index(['age', 'gender', 'course', 'study_hours', 'class_attendance',\n",
      "       'internet_access', 'sleep_hours', 'sleep_quality', 'study_method',\n",
      "       'facility_rating', 'exam_difficulty', 'orig_mean_age', 'orig_count_age',\n",
      "       'orig_mean_gender', 'orig_count_gender', 'orig_mean_course',\n",
      "       'orig_count_course', 'orig_mean_study_hours', 'orig_count_study_hours',\n",
      "       'orig_mean_class_attendance', 'orig_count_class_attendance',\n",
      "       'orig_mean_internet_access', 'orig_count_internet_access',\n",
      "       'orig_mean_sleep_hours', 'orig_count_sleep_hours',\n",
      "       'orig_mean_sleep_quality', 'orig_count_sleep_quality',\n",
      "       'orig_mean_study_method', 'orig_count_study_method',\n",
      "       'orig_mean_facility_rating', 'orig_count_facility_rating',\n",
      "       'orig_mean_exam_difficulty', 'orig_count_exam_difficulty', 'te_gender',\n",
      "       'te_course', 'te_sleep_quality', 'te_study_method',\n",
      "       'te_facility_rating', 'te_exam_difficulty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Target Encoding (OOFでリーク防止) + 列選別条件つき\n",
    "# =========================\n",
    "\n",
    "def select_te_cols(\n",
    "    df_train, df_test, cols,\n",
    "    min_unique=3,              # unique <=2 は除外\n",
    "    max_unique_abs=5000,       # 高カーディナリティ除外\n",
    "    max_unique_ratio=0.30,     # unique/行数 が大きすぎる列は除外（ID化）\n",
    "    max_missing=0.60,          # 欠損率が高い列は除外\n",
    "    rare_thr=5,                # レア判定（出現回数<=5）\n",
    "    max_rare_points_ratio=0.80,# レアカテゴリが占める割合が大きい列は除外\n",
    "    max_unseen_ratio=0.20      # testにしかないカテゴリが多い列は除外\n",
    "):\n",
    "    n = len(df_train)\n",
    "    chosen = []\n",
    "    for col in cols:\n",
    "        s_tr = df_train[col]\n",
    "        s_te = df_test[col]\n",
    "\n",
    "        # 欠損\n",
    "        if s_tr.isna().mean() > max_missing:\n",
    "            continue\n",
    "\n",
    "        # unique\n",
    "        nunq = s_tr.nunique(dropna=True)\n",
    "        if nunq < min_unique:\n",
    "            continue\n",
    "        if nunq > max_unique_abs:\n",
    "            continue\n",
    "        if nunq / n > max_unique_ratio:\n",
    "            continue\n",
    "\n",
    "        # レアカテゴリ比率\n",
    "        vc = s_tr.value_counts(dropna=True)\n",
    "        rare_points_ratio = (s_tr.map(vc).fillna(0) <= rare_thr).mean()\n",
    "        if rare_points_ratio > max_rare_points_ratio:\n",
    "            continue\n",
    "\n",
    "        # unseen比率（testにあるがtrainにないカテゴリの比率）\n",
    "        tr_set = set(s_tr.dropna().unique())\n",
    "        te_set = set(s_te.dropna().unique())\n",
    "        if len(te_set) > 0:\n",
    "            unseen_ratio = len(te_set - tr_set) / len(te_set)\n",
    "            if unseen_ratio > max_unseen_ratio:\n",
    "                continue\n",
    "\n",
    "        chosen.append(col)\n",
    "    return chosen\n",
    "\n",
    "\n",
    "def add_target_encoding_oof(train_df, test_df, y, te_cols, n_splits=5, seed=42, smoothing=20):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    for col in te_cols:\n",
    "        te_name = f\"te_{col}\"\n",
    "        train_te = np.zeros(len(train_df), dtype=np.float64)\n",
    "        test_te_folds = []\n",
    "\n",
    "        for tr_idx, va_idx in kf.split(train_df):\n",
    "            X_tr = train_df.iloc[tr_idx]\n",
    "            y_tr = y.iloc[tr_idx]\n",
    "            X_va = train_df.iloc[va_idx]\n",
    "\n",
    "            prior = y_tr.mean()\n",
    "\n",
    "            stats = (\n",
    "                pd.DataFrame({col: X_tr[col].values, \"y\": y_tr.values})\n",
    "                .groupby(col)[\"y\"]\n",
    "                .agg([\"mean\", \"count\"])\n",
    "            )\n",
    "\n",
    "            smooth_map = (stats[\"count\"] * stats[\"mean\"] + smoothing * prior) / (stats[\"count\"] + smoothing)\n",
    "\n",
    "            train_te[va_idx] = X_va[col].map(smooth_map).fillna(prior).astype(np.float64).values\n",
    "            test_te_folds.append(test_df[col].map(smooth_map).fillna(prior).astype(np.float64).values)\n",
    "\n",
    "        train_df[te_name] = train_te\n",
    "        test_df[te_name] = np.mean(np.vstack(test_te_folds), axis=0)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# ---- ここがあなたのコードの差し替え部分 ----\n",
    "\n",
    "# TE対象を「object列のうち、条件を満たす列」に絞る\n",
    "TE_COLS_RAW = categories\n",
    "TE_COLS = select_te_cols(\n",
    "    train, test, TE_COLS_RAW,\n",
    "    min_unique=3,\n",
    "    max_unique_abs=5000,\n",
    "    max_unique_ratio=0.30,\n",
    "    max_missing=0.60,\n",
    "    rare_thr=5,\n",
    "    max_rare_points_ratio=0.80,\n",
    "    max_unseen_ratio=0.20\n",
    ")\n",
    "print(f\"Target Encoding applied to {len(TE_COLS)} features.\")\n",
    "print(\"TE_COLS:\", TE_COLS)\n",
    "\n",
    "# OOF TE作成\n",
    "train, test = add_target_encoding_oof(train, test, y, TE_COLS, n_splits=5, seed=42, smoothing=20)\n",
    "\n",
    "TE_FEATURES = [f\"te_{c}\" for c in TE_COLS]\n",
    "features = base + ORIG + TE_FEATURES\n",
    "\n",
    "X = train[features].copy()\n",
    "y = train[target].copy()\n",
    "X_test = test[features].copy()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(X.columns)\n",
    "print(X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3db34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:8.83617\n",
      "[200]\tvalidation_0-rmse:8.79972\n",
      "[400]\tvalidation_0-rmse:8.78195\n",
      "[600]\tvalidation_0-rmse:8.77016\n",
      "[800]\tvalidation_0-rmse:8.76038\n",
      "[1000]\tvalidation_0-rmse:8.75169\n",
      "[1200]\tvalidation_0-rmse:8.74433\n",
      "[1400]\tvalidation_0-rmse:8.73851\n",
      "[1600]\tvalidation_0-rmse:8.73309\n",
      "[1800]\tvalidation_0-rmse:8.72833\n",
      "[2000]\tvalidation_0-rmse:8.72396\n",
      "[2200]\tvalidation_0-rmse:8.72059\n",
      "[2400]\tvalidation_0-rmse:8.71744\n",
      "[2600]\tvalidation_0-rmse:8.71456\n",
      "[2800]\tvalidation_0-rmse:8.71177\n",
      "[3000]\tvalidation_0-rmse:8.70922\n",
      "[3200]\tvalidation_0-rmse:8.70699\n",
      "[3400]\tvalidation_0-rmse:8.70481\n",
      "[3600]\tvalidation_0-rmse:8.70298\n",
      "[3800]\tvalidation_0-rmse:8.70124\n",
      "[4000]\tvalidation_0-rmse:8.70004\n",
      "[4200]\tvalidation_0-rmse:8.69864\n",
      "[4400]\tvalidation_0-rmse:8.69738\n",
      "[4600]\tvalidation_0-rmse:8.69593\n",
      "[4800]\tvalidation_0-rmse:8.69508\n",
      "[4999]\tvalidation_0-rmse:8.69393\n",
      "Fold 1 RMSE: 8.69393\n",
      "[0]\tvalidation_0-rmse:8.83989\n",
      "[200]\tvalidation_0-rmse:8.80435\n",
      "[400]\tvalidation_0-rmse:8.78816\n",
      "[600]\tvalidation_0-rmse:8.77659\n",
      "[800]\tvalidation_0-rmse:8.76671\n",
      "[1000]\tvalidation_0-rmse:8.75817\n",
      "[1200]\tvalidation_0-rmse:8.75123\n",
      "[1400]\tvalidation_0-rmse:8.74521\n",
      "[1600]\tvalidation_0-rmse:8.74013\n",
      "[1800]\tvalidation_0-rmse:8.73548\n",
      "[2000]\tvalidation_0-rmse:8.73146\n",
      "[2200]\tvalidation_0-rmse:8.72787\n",
      "[2400]\tvalidation_0-rmse:8.72455\n",
      "[2600]\tvalidation_0-rmse:8.72157\n",
      "[2800]\tvalidation_0-rmse:8.71886\n",
      "[3000]\tvalidation_0-rmse:8.71663\n",
      "[3200]\tvalidation_0-rmse:8.71471\n",
      "[3400]\tvalidation_0-rmse:8.71254\n",
      "[3600]\tvalidation_0-rmse:8.71073\n",
      "[3800]\tvalidation_0-rmse:8.70885\n",
      "[4000]\tvalidation_0-rmse:8.70750\n",
      "[4200]\tvalidation_0-rmse:8.70596\n",
      "[4400]\tvalidation_0-rmse:8.70465\n",
      "[4600]\tvalidation_0-rmse:8.70302\n",
      "[4800]\tvalidation_0-rmse:8.70166\n",
      "[4999]\tvalidation_0-rmse:8.70068\n",
      "Fold 2 RMSE: 8.70068\n",
      "[0]\tvalidation_0-rmse:8.83442\n",
      "[200]\tvalidation_0-rmse:8.79850\n",
      "[400]\tvalidation_0-rmse:8.78131\n",
      "[600]\tvalidation_0-rmse:8.76874\n",
      "[800]\tvalidation_0-rmse:8.75844\n",
      "[1000]\tvalidation_0-rmse:8.74963\n",
      "[1200]\tvalidation_0-rmse:8.74286\n",
      "[1400]\tvalidation_0-rmse:8.73674\n",
      "[1600]\tvalidation_0-rmse:8.73159\n",
      "[1800]\tvalidation_0-rmse:8.72679\n",
      "[2000]\tvalidation_0-rmse:8.72262\n",
      "[2200]\tvalidation_0-rmse:8.71883\n",
      "[2400]\tvalidation_0-rmse:8.71593\n",
      "[2600]\tvalidation_0-rmse:8.71333\n",
      "[2800]\tvalidation_0-rmse:8.71071\n",
      "[3000]\tvalidation_0-rmse:8.70857\n",
      "[3200]\tvalidation_0-rmse:8.70641\n",
      "[3400]\tvalidation_0-rmse:8.70458\n",
      "[3600]\tvalidation_0-rmse:8.70299\n",
      "[3800]\tvalidation_0-rmse:8.70117\n",
      "[4000]\tvalidation_0-rmse:8.69971\n",
      "[4200]\tvalidation_0-rmse:8.69858\n",
      "[4400]\tvalidation_0-rmse:8.69732\n",
      "[4600]\tvalidation_0-rmse:8.69616\n",
      "[4800]\tvalidation_0-rmse:8.69494\n",
      "[4999]\tvalidation_0-rmse:8.69382\n",
      "Fold 3 RMSE: 8.69381\n",
      "[0]\tvalidation_0-rmse:8.84954\n",
      "[200]\tvalidation_0-rmse:8.81358\n",
      "[400]\tvalidation_0-rmse:8.79748\n",
      "[600]\tvalidation_0-rmse:8.78396\n",
      "[800]\tvalidation_0-rmse:8.77425\n",
      "[1000]\tvalidation_0-rmse:8.76606\n",
      "[1200]\tvalidation_0-rmse:8.75902\n",
      "[1400]\tvalidation_0-rmse:8.75314\n",
      "[1600]\tvalidation_0-rmse:8.74822\n",
      "[1800]\tvalidation_0-rmse:8.74349\n",
      "[2000]\tvalidation_0-rmse:8.73948\n",
      "[2200]\tvalidation_0-rmse:8.73615\n",
      "[2400]\tvalidation_0-rmse:8.73245\n",
      "[2600]\tvalidation_0-rmse:8.72959\n",
      "[2800]\tvalidation_0-rmse:8.72686\n",
      "[3000]\tvalidation_0-rmse:8.72425\n",
      "[3200]\tvalidation_0-rmse:8.72180\n",
      "[3400]\tvalidation_0-rmse:8.71967\n",
      "[3600]\tvalidation_0-rmse:8.71779\n",
      "[3800]\tvalidation_0-rmse:8.71611\n",
      "[4000]\tvalidation_0-rmse:8.71444\n",
      "[4200]\tvalidation_0-rmse:8.71270\n",
      "[4400]\tvalidation_0-rmse:8.71126\n",
      "[4600]\tvalidation_0-rmse:8.70980\n",
      "[4800]\tvalidation_0-rmse:8.70870\n",
      "[4999]\tvalidation_0-rmse:8.70758\n",
      "Fold 4 RMSE: 8.70758\n",
      "[0]\tvalidation_0-rmse:8.86251\n",
      "[200]\tvalidation_0-rmse:8.82671\n",
      "[400]\tvalidation_0-rmse:8.80977\n",
      "[600]\tvalidation_0-rmse:8.79832\n",
      "[800]\tvalidation_0-rmse:8.78846\n",
      "[1000]\tvalidation_0-rmse:8.78023\n",
      "[1200]\tvalidation_0-rmse:8.77291\n",
      "[1400]\tvalidation_0-rmse:8.76737\n",
      "[1600]\tvalidation_0-rmse:8.76229\n",
      "[1800]\tvalidation_0-rmse:8.75775\n",
      "[2000]\tvalidation_0-rmse:8.75381\n",
      "[2200]\tvalidation_0-rmse:8.75013\n",
      "[2400]\tvalidation_0-rmse:8.74717\n",
      "[2600]\tvalidation_0-rmse:8.74444\n",
      "[2800]\tvalidation_0-rmse:8.74171\n",
      "[3000]\tvalidation_0-rmse:8.73934\n",
      "[3200]\tvalidation_0-rmse:8.73723\n",
      "[3400]\tvalidation_0-rmse:8.73535\n",
      "[3600]\tvalidation_0-rmse:8.73389\n",
      "[3800]\tvalidation_0-rmse:8.73214\n",
      "[4000]\tvalidation_0-rmse:8.73059\n",
      "[4200]\tvalidation_0-rmse:8.72901\n",
      "[4400]\tvalidation_0-rmse:8.72762\n",
      "[4600]\tvalidation_0-rmse:8.72633\n",
      "[4800]\tvalidation_0-rmse:8.72506\n",
      "[4999]\tvalidation_0-rmse:8.72394\n",
      "Fold 5 RMSE: 8.72394\n",
      "------------------------------\n",
      "OOF RMSE: 8.70399\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 非線形モデル例（どれか1つでOK）\n",
    "from xgboost import XGBRegressor\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) 前提: X, y, X_test が既にできている想定\n",
    "#   X: train特徴量(DataFrame)\n",
    "#   y: target(Series)\n",
    "#   X_test: test特徴量(DataFrame)\n",
    "# =========================\n",
    "\n",
    "# カラム型を自動判定（object/category をカテゴリ扱い）\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 1段目（線形）と 2段目（残差）のOOFを作る\n",
    "oof_linear = np.zeros(len(X))\n",
    "oof_resid  = np.zeros(len(X))\n",
    "test_linear_folds = []\n",
    "test_resid_folds  = []\n",
    "\n",
    "# =========================\n",
    "# 1) 線形モデル（Ridge推奨）\n",
    "# =========================\n",
    "linear_model = Pipeline(steps=[\n",
    "    (\"pre\", ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols),\n",
    "        ]\n",
    "    )),\n",
    "    (\"ridge\", Ridge(alpha=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# 2) 残差モデル（XGB / LGBM / MLP）\n",
    "#   ここではXGB例（カテゴリは factorize して数値化）\n",
    "# =========================\n",
    "xgb_params = dict(\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"rmse\",\n",
    "    early_stopping_rounds=200,\n",
    ")\n",
    "\n",
    "def factorize_fit_transform(train_df, val_df, test_df, cat_cols):\n",
    "    \"\"\"fold内でリークしないように、train+val+test を結合して factorize して整合を取る\"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    val_df   = val_df.copy()\n",
    "    test_df  = test_df.copy()\n",
    "\n",
    "    for c in cat_cols:\n",
    "        comb = pd.concat([train_df[c], val_df[c], test_df[c]], axis=0)\n",
    "        codes, _ = comb.factorize(sort=True)\n",
    "        n_tr = len(train_df)\n",
    "        n_va = len(val_df)\n",
    "\n",
    "        train_df[c] = codes[:n_tr]\n",
    "        val_df[c]   = codes[n_tr:n_tr+n_va]\n",
    "        test_df[c]  = codes[n_tr+n_va:]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) CV学習: 線形→残差→合成\n",
    "# =========================\n",
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(X, y), 1):\n",
    "    X_tr, y_tr = X.iloc[tr_idx].copy(), y.iloc[tr_idx].copy()\n",
    "    X_va, y_va = X.iloc[va_idx].copy(), y.iloc[va_idx].copy()\n",
    "\n",
    "    # ---- (A) 線形 fit -> pred ----\n",
    "    linear_model.fit(X_tr, y_tr)\n",
    "    pred_lin_va = linear_model.predict(X_va)\n",
    "    oof_linear[va_idx] = pred_lin_va\n",
    "\n",
    "    # testの線形pred（fold平均）\n",
    "    pred_lin_te = linear_model.predict(X_test)\n",
    "    test_linear_folds.append(pred_lin_te)\n",
    "\n",
    "    # ---- (B) 残差を作る ----\n",
    "    resid_tr = y_tr - linear_model.predict(X_tr)\n",
    "    resid_va_true = y_va - pred_lin_va  # 評価用\n",
    "\n",
    "    # ---- (C) 残差モデル fit -> pred ----\n",
    "    # XGB用にカテゴリを数値化（fold内で整合）\n",
    "    X_tr2, X_va2, X_te2 = factorize_fit_transform(X_tr, X_va, X_test, cat_cols)\n",
    "\n",
    "    resid_model = XGBRegressor(**xgb_params)\n",
    "    resid_model.fit(\n",
    "        X_tr2, resid_tr,\n",
    "        eval_set=[(X_va2, resid_va_true)],\n",
    "        verbose=200\n",
    "    )\n",
    "\n",
    "    pred_resid_va = resid_model.predict(X_va2)\n",
    "    oof_resid[va_idx] = pred_resid_va\n",
    "\n",
    "    pred_resid_te = resid_model.predict(X_te2)\n",
    "    test_resid_folds.append(pred_resid_te)\n",
    "\n",
    "    # ---- (D) 合成 ----\n",
    "    pred_final_va = pred_lin_va + pred_resid_va\n",
    "    rmse = np.sqrt(mean_squared_error(y_va, pred_final_va))\n",
    "    print(f\"Fold {fold} RMSE: {rmse:.5f}\")\n",
    "\n",
    "# 全体OOF\n",
    "oof_final = oof_linear + oof_resid\n",
    "print(\"-\"*30)\n",
    "print(f\"OOF RMSE: {np.sqrt(mean_squared_error(y, oof_final)):.5f}\")\n",
    "\n",
    "# test予測（fold平均）\n",
    "test_linear = np.mean(np.vstack(test_linear_folds), axis=0)\n",
    "test_resid  = np.mean(np.vstack(test_resid_folds), axis=0)\n",
    "test_pred   = test_linear + test_resid\n",
    "\n",
    "# 送信用（id列名は適宜）\n",
    "# sub = pd.DataFrame({\"id\": test[\"id\"], \"exam_score\": test_pred})\n",
    "# sub.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46f89f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630000</td>\n",
       "      <td>70.958174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630001</td>\n",
       "      <td>69.800803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630002</td>\n",
       "      <td>88.742019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630003</td>\n",
       "      <td>55.147936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630004</td>\n",
       "      <td>45.419446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  exam_score\n",
       "0  630000   70.958174\n",
       "1  630001   69.800803\n",
       "2  630002   88.742019\n",
       "3  630003   55.147936\n",
       "4  630004   45.419446"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission 作成（id列は自動で推定して作る）\n",
    "pred_col = target  # 'exam_score'\n",
    "\n",
    "# id列名を推定\n",
    "id_col = \"id\" if \"id\" in test.columns else (\"Id\" if \"Id\" in test.columns else None)\n",
    "if id_col is None:\n",
    "    raise ValueError(\"testに id / Id 列が見つかりません。id列名を手動で指定してください。\")\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    id_col: test[id_col].values,\n",
    "    pred_col: test_pred  # 直前で作った最終予測（線形 + 残差）\n",
    "})\n",
    "\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
